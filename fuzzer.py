# fuzzer.py
# main 입니다.

from config import*
from CodeGenerator import generate_c_code
from Analyzer import analyze_results
from running_system import*
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from queue import Queue
import logging
import uuid
import argparse
from itertools import repeat

logging.basicConfig(level=logging.WARNING)
# process_generator 함수: 생성기 별로 퍼징을 수행하는 함수
# argv: generator - 생성기 종류 (현재 csmith와 yarpgen)
# return: None 
def process_generator(generator, partial_timeout=True):
    machine_info = get_machine_info()
    round_number = 0  # 라운드 번호 초기화
    
    while True:
        print(f"\n{'#'*100}")
        print(f"[*] Fuzzing round: {round_number} for generator: {generator}")
        print(f"{'#'*100}\n")
        
        completed_tasks = 0
        skipped_tasks = 0
        
        try:
            for index in range(0, total_tasks):
                #result_queue = Queue()  # 스레드 안전한 큐 생성
                # 소스코드 생성
                print(f"****************************************generated by {generator}: {index} task started*********************************************")
                id = uuid.uuid1()    # 고유한 ID 셍성 - 어떤 컴퓨터에서 생성하든 생성된 코드를 구분하기 위함 
                filepath, random_seed = generate_c_code(id, generator)
                # 코드 생성이 되지 않은 경우 예외 처리 
                if filepath is None:
                    logging.warning(f"Code generation failed for task {index} using {generator}, skipping.")
                    skipped_tasks += 1
                    continue
                #logging.info(f"Source code generated for task {index} using {generator}: {filepath}")
                #logging.info(f"Submitting tasks for compilation and execution for task {index}")
                
                with ProcessPoolExecutor() as executor:
                    futures = []
                    results = {}
                    # 컴파일 및 실행 (gcc, clang으로 -O0 ~ -O3 옵션 주어서 컴파일 하고 실행 결과 저장)
                    for compiler in compilers:
                        for opt_level in optimization_levels:
                            futures.append(executor.submit(compile_and_run, filepath, generator, id, compiler, opt_level, random_seed))
                            
                    for future in futures:
                        result = future.result()
                        if result is not None:
                            key, result_dict = result
                            if key == "error": # 에러 처리
                                continue
                            results[key] = result_dict
                
                if len(results) > 0:  # results 딕셔너리가 비어 있지 않다면
                    analyze_results(generator, id, random_seed, results, machine_info, partial_timeout)
                else:
                    # results 딕셔너리가 비어 있는 경우, 문제가 발생한 것으로 판단
                    skipped_tasks += 1
                    logging.critical(f"CRITICAL ERROR: This is an exceptional case which means impossible and requires immediate attention.")
                
                # Temp 폴더 청소
                #logging.info(f"Temp files cleaned for task {index}")
                cleanup_temp(generator)
                # 진행률 업데이트 및 출력
                completed_tasks += 1
                progress = (completed_tasks / total_tasks) * 100
                print(f"Progress for {generator}: {progress:.2f}% completed. skipped count: {skipped_tasks}")
                print(f"****************************************generated by {generator}: {index} task finished*********************************************")
            round_number += 1  # 라운드 번호 증가   
        except Exception as e:
            logging.error(f"An unexpected error occurred in process_generator for generator {generator} and task {index}: {e}")


# main 함수: 퍼징을 수행하는 총괄 코드
def main():
    parser = argparse.ArgumentParser(description="Analyze results.")
    parser.add_argument("--no-timeout", action="store_false", dest="partial_timeout")
    args = parser.parse_args()
    # 디렉토리 초기화
    setup_output_dirs(generators)
    with ThreadPoolExecutor() as executor:
        executor.map(process_generator, generators, repeat(args.partial_timeout))

if __name__ == "__main__":
    main()


